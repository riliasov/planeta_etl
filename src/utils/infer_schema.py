"""–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ SQL-—Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ Google Sheets."""
import pandas as pd
import re
from dateutil import parser

from src.config import load_config
from src.sheets import get_sheets_client, read_sheet_data

def infer_sql_type(series):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç SQL —Ç–∏–ø –¥–ª—è pandas Series.
    """
    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    clean_series = series.dropna().astype(str)
    clean_series = clean_series[clean_series != '']
    
    if len(clean_series) == 0:
        return "TEXT" # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –ø—É—Å—Ç–æ

    sample = clean_series.tolist()
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ BOOLEAN (–î–∞/–ù–µ—Ç, True/False)
    bool_patterns = {'true', 'false', '–¥–∞', '–Ω–µ—Ç', 'yes', 'no', '+', '-'}
    if all(str(x).lower() in bool_patterns for x in sample):
        return "BOOLEAN"

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ INTEGER
    # –†–∞–∑—Ä–µ—à–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Ç—ã—Å—è—á "1 000"
    try:
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–∏—Å–ª–æ–º
        cleaned_nums = [x.replace(' ', '').replace('\xa0', '') for x in sample]
        if all(x.isdigit() or (x.startswith('-') and x[1:].isdigit()) for x in cleaned_nums):
            return "INTEGER"
    except:
        pass

    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NUMERIC/FLOAT
    try:
        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É, —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
        cleaned_floats = [x.replace(',', '.').replace(' ', '').replace('\xa0', '') for x in sample]
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
        pd.to_numeric(cleaned_floats)
        return "NUMERIC(10,2)"
    except:
        pass

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ DATE / TIMESTAMP
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—Ç—ã DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD
    date_pattern = re.compile(r'^\d{1,2}[./-]\d{1,2}[./-]\d{2,4}(\s\d{1,2}:\d{2})?$')
    if all(bool(date_pattern.match(str(x).strip())) for x in sample[:50]): # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 50 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
        try:
            for x in sample[:20]:
                parser.parse(str(x), dayfirst=True)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º—è - TIMESTAMP, –∏–Ω–∞—á–µ DATE
            if any(':' in str(x) for x in sample[:20]):
                return "TIMESTAMP"
            return "DATE"
        except:
            pass

    # 5. Fallback
    return "TEXT"

def clean_column_name(col_name):
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç '–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è' –≤ 'data_rozhdeniya' –∏–ª–∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç"""
    if not col_name:
        return "col_unknown"
    
    # –ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞
    mapping = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        ' ': '_', '-': '_', '.': '', ',': '', '/': '_', '(': '', ')': ''
    }
    
    clean = str(col_name).lower()
    result = ''
    for char in clean:
        result += mapping.get(char, char)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
    result = re.sub(r'[^a-z0-9_]', '', result)
    result = re.sub(r'_+', '_', result).strip('_')
    
    # –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Ü–∏—Ñ—Ä—ã, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å
    if result and result[0].isdigit():
        result = 'col_' + result
        
    return result or "col_unnamed"

def analyze_sources():
    print("üïµÔ∏è‚Äç‚ôÇÔ∏è –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö...\n")
    
    config = load_config()
    gc = get_sheets_client(config)
    sources = config.get('SOURCES', {})
    
    schema_definitions = {}
    
    for source_name, source_config in sources.items():
        print(f"üì¶ –ê–Ω–∞–ª–∏–∑ {source_name}...")
        
        spreadsheet_id = source_config.get('spreadsheet_id')
        sheet_identifiers = source_config.get('sheet_identifiers', [])
        ranges = source_config.get('ranges', {})
        use_gid = source_config.get('use_gid', False)
        
        if not sheet_identifiers or spreadsheet_id.startswith("–£–ö–ê–ñ–ò–¢–ï"):
            print(f"   ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ (–Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)")
            continue
            
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã
        sheet_id = sheet_identifiers[0]
        range_name = ranges.get(sheet_id)
        
        try:
            data = read_sheet_data(gc, spreadsheet_id, sheet_id, range_name, use_gid)
            if not data or len(data) < 2:
                print("   ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
                continue
                
            headers = data[0]
            # –°–æ–∑–¥–∞–µ–º DataFrame
            df = pd.DataFrame(data[1:], columns=headers)
            
            table_schema = []
            
            for col in df.columns:
                sql_type = infer_sql_type(df[col])
                clean_name = clean_column_name(col)
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫
                original_clean_name = clean_name
                counter = 1
                existing_names = [x['name'] for x in table_schema]
                while clean_name in existing_names:
                    clean_name = f"{original_clean_name}_{counter}"
                    counter += 1
                
                table_schema.append({
                    "original": col,
                    "name": clean_name,
                    "type": sql_type
                })
            
            schema_definitions[source_name] = table_schema
            print(f"   ‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ {len(table_schema)} –∫–æ–ª–æ–Ω–æ–∫")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL
    print("\n" + "="*50)
    print("–ü–†–ï–î–õ–ê–ì–ê–ï–ú–ê–Ø –°–•–ï–ú–ê STAGING (SILVER LAYER)")
    print("="*50 + "\n")
    
    sql_output = ""
    
    for table, columns in schema_definitions.items():
        sql_output += f"-- –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è {table}\n"
        sql_output += f"CREATE TABLE IF NOT EXISTS staging.{table} (\n"
        sql_output += "    id SERIAL PRIMARY KEY,\n"
        sql_output += "    source_row_id INTEGER,\n"
        
        for col in columns:
            sql_output += f"    {col['name']:<30} {col['type']},\n"
            
        sql_output += "    imported_at TIMESTAMP DEFAULT NOW()\n"
        sql_output += ");\n\n"
        
        # –í—ã–≤–æ–¥ –º–∞–ø–ø–∏–Ω–≥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        print(f"üìå {table}")
        for col in columns:
            print(f"   {col['original']:<30} -> {col['name']:<30} {col['type']}")
        print("-" * 50)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    with open('src/db/inferred_schema.sql', 'w', encoding='utf-8') as f:
        f.write("CREATE SCHEMA IF NOT EXISTS staging;\n\n")
        f.write(sql_output)
        
    print("\nüíæ SQL —Å—Ö–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ src/db/inferred_schema.sql")

if __name__ == '__main__':
    analyze_sources()
