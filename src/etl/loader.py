import hashlib
import json
import pandas as pd
import sqlalchemy
from sqlalchemy import text
from datetime import datetime

from src.logger import get_logger
logger = get_logger(__name__)

class DataLoader:
    def __init__(self, db_engine):
        self.engine = db_engine

    def calculate_row_hash(self, row_dict):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç MD5 —Ö—ç—à —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç JSON –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏.
        """
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–∏, —á—Ç–æ–±—ã –ø–æ—Ä—è–¥–æ–∫ –Ω–µ –≤–ª–∏—è–ª –Ω–∞ —Ö—ç—à
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç—Ä–æ–∫—É, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å —Ç–∏–ø–∞–º–∏
        row_str = json.dumps(row_dict, sort_keys=True, default=str, ensure_ascii=False)
        return hashlib.md5(row_str.encode('utf-8')).hexdigest()

    def load_staging(self, df, table_name, source_name):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç DataFrame –≤ staging —Ç–∞–±–ª–∏—Ü—É —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π.
        
        Args:
            df (pd.DataFrame): –î–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            table_name (str): –ò–º—è —Ç–∞–±–ª–∏—Ü—ã –≤ staging —Å—Ö–µ–º–µ (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ staging.)
            source_name (str): –ò–º—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–¥–ª—è –ª–æ–≥–æ–≤)
        """
        if df.empty:
            logger.info(f"‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ {table_name}")
            return 0

        logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ {len(df)} —Å—Ç—Ä–æ–∫ –≤ staging.{table_name}...")

        # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        # –î–æ–±–∞–≤–ª—è–µ–º row_hash
        records = df.to_dict(orient='records')
        for row in records:
            row['row_hash'] = self.calculate_row_hash(row)
            
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ DF –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ (–∏–ª–∏ –º–æ–∂–Ω–æ –≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–∫–æ–º —Å–ª–æ–≤–∞—Ä–µ–π)
        df_to_load = pd.DataFrame(records)
        
        # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ö—ç—à–µ–π (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
        # –≠—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –≤–º–µ—Å—Ç–æ INSERT ON CONFLICT –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏,
        # –º—ã —Å–Ω–∞—á–∞–ª–∞ —É–∑–Ω–∞–µ–º, –∫–∞–∫–∏–µ —Ö—ç—à–∏ —É–∂–µ –µ—Å—Ç—å, –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –∏—Ö.
        # –î–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞–∫–ª–∞–¥–Ω–æ, –Ω–æ –¥–ª—è 20-50–∫ —Å—Ç—Ä–æ–∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ.
        
        existing_hashes = set()
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text(f"SELECT row_hash FROM staging.{table_name}"))
                existing_hashes = {row[0] for row in result}
        except Exception as e:
            logger.error(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ö—ç—à–µ–π (–≤–æ–∑–º–æ–∂–Ω–æ —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞): {e}")

        # 3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫
        new_records = [
            row for row in records 
            if row['row_hash'] not in existing_hashes
        ]
        
        if not new_records:
            logger.info(f"   ‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {table_name} (–≤—Å–µ {len(records)} —Å—Ç—Ä–æ–∫ —É–∂–µ –≤ –±–∞–∑–µ)")
            return 0
            
        logger.info(f"   üöÄ –ù–∞–π–¥–µ–Ω–æ {len(new_records)} –Ω–æ–≤—ã—Ö/–∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫. –í—Å—Ç–∞–≤–∫–∞...")
        
        # 4. –í—Å—Ç–∞–≤–∫–∞ (Bulk Insert)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º pandas to_sql –∏–ª–∏ sqlalchemy insert
        # Pandas to_sql —Å method='multi' —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ–ø–ª–æ—Ö–æ –¥–ª—è postgres
        
        df_new = pd.DataFrame(new_records)
        
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –ë–î (–ª–∏—à–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ pandas –º–æ–≥—É—Ç –≤—ã–∑–≤–∞—Ç—å –æ—à–∏–±–∫—É)
        # –í –∏–¥–µ–∞–ª–µ –Ω—É–∂–Ω–æ –º–∞–ø–ø–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏, –Ω–æ –ø–æ–∫–∞ –ø–æ–ª–∞–≥–∞–µ–º—Å—è –Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–º–µ–Ω –∏–∑ infer_schema
        
        try:
            df_new.to_sql(
                table_name,
                self.engine,
                schema='staging',
                if_exists='append',
                index=False,
                method='multi',
                chunksize=1000 # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞—á–∫–∏
            )
            logger.info(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(new_records)} —Å—Ç—Ä–æ–∫.")
            return len(new_records)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –≤ {table_name}: {e}")
            return 0

    def load_raw_json(self, data_list, table_name, spreadsheet_id, sheet_id):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ raw —Ç–∞–±–ª–∏—Ü—É (JSONB).
        –ó–¥–µ—Å—å –º—ã –æ–±—ã—á–Ω–æ –¥–µ–ª–∞–µ–º TRUNCATE + INSERT –∏–ª–∏ Append Only.
        –î–ª—è raw –∏—Å—Ç–æ—Ä–∏–∏ –ª—É—á—à–µ Append Only –∏–ª–∏ –ø–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∑–∞–ª–∏–≤–∫–∞.
        """
        # –ü–æ–∫–∞ –ø—Ä–æ–ø—É—Å—Ç–∏–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é raw, —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–º—Å—è –Ω–∞ staging
        pass
